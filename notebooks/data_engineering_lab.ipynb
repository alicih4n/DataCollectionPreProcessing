{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Hello, Data!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the raw CSV data (Sales + Shipping/Promo) to simulate a real-world integration task.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885abbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pprint\n",
    "\n",
    "sales_path = '../data/sales_data.csv'\n",
    "promo_path = '../data/shipping_promo_data.csv'\n",
    "\n",
    "# Load Sales Data\n",
    "sales_data = []\n",
    "with open(sales_path, mode='r', encoding='utf-8') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in reader:\n",
    "        sales_data.append(row)\n",
    "\n",
    "# Load Promo/Shipping Data\n",
    "promo_data = {}\n",
    "with open(promo_path, mode='r', encoding='utf-8') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in reader:\n",
    "        # Index by Order ID for fast merging\n",
    "        promo_data[row['Order ID']] = row\n",
    "\n",
    "print(f\"Loaded {len(sales_data)} sales records.\")\n",
    "print(f\"Loaded {len(promo_data)} shipping/promo records.\")\n",
    "pprint.pprint(sales_data[0])\n",
    "pprint.pprint(promo_data[sales_data[0]['Order ID']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb1fe05",
   "metadata": {},
   "source": [
    "## Step 2: Pick the Right Container\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad843cd",
   "metadata": {},
   "source": [
    "**Justification:**\n",
    "1.  **Sales Data**: Dictionary list for sequential processing.\n",
    "2.  **Promo Data**: **Dictionary of Dictionaries** (Hash Map) using `Order ID` as key. This allows O(1) lookups during the merge phase, which is much faster than looping through lists (O(N^2)).\n",
    "This design mimics database index lookups.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c6f98a",
   "metadata": {},
   "source": [
    "## Step 3: Implement Functions and Data structure\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e788dde",
   "metadata": {},
   "source": [
    "We update our `Transaction` class to include the merged fields: `shipping_city` and `coupon_code`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abddac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transaction:\n",
    "    def __init__(self, sales_row, promo_row=None):\n",
    "        # Base Sales Data\n",
    "        self.region = sales_row.get('Region')\n",
    "        self.country = sales_row.get('Country')\n",
    "        self.item_type = sales_row.get('Item Type')\n",
    "        self.sales_channel = sales_row.get('Sales Channel')\n",
    "        self.order_date = sales_row.get('Order Date')\n",
    "        self.order_id = sales_row.get('Order ID')\n",
    "        self.units_sold = sales_row.get('Units Sold')\n",
    "        self.unit_price = sales_row.get('Unit Price')\n",
    "        self.unit_cost = sales_row.get('Unit Cost')\n",
    "        self.total_revenue = sales_row.get('Total Revenue')\n",
    "        self.total_cost = sales_row.get('Total Cost')\n",
    "        self.total_profit = sales_row.get('Total Profit')\n",
    "        \n",
    "        # Merged Data (if available)\n",
    "        if promo_row:\n",
    "            self.shipping_city = promo_row.get('Shipping City')\n",
    "            self.coupon_code = promo_row.get('Coupon Code')\n",
    "        else:\n",
    "            self.shipping_city = None\n",
    "            self.coupon_code = None\n",
    "            \n",
    "        # Additional fields for processing\n",
    "        self.discount_amount = 0.0\n",
    "\n",
    "    def clean(self):\n",
    "        # Type conversions\n",
    "        if isinstance(self.units_sold, str):\n",
    "            try:\n",
    "                self.units_sold = int(self.units_sold)\n",
    "            except ValueError:\n",
    "                self.units_sold = 0\n",
    "        \n",
    "        for field in ['unit_price', 'unit_cost', 'total_revenue', 'total_cost', 'total_profit']:\n",
    "            val = getattr(self, field)\n",
    "            if isinstance(val, str):\n",
    "                try:\n",
    "                    setattr(self, field, float(val))\n",
    "                except ValueError:\n",
    "                    setattr(self, field, 0.0)\n",
    "        \n",
    "        # City Cleaning: Standardize Title Case\n",
    "        if self.shipping_city:\n",
    "            self.shipping_city = self.shipping_city.title().strip()\n",
    "\n",
    "    def total(self):\n",
    "        return self.total_revenue\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"<Transaction {self.order_id} | City: {self.shipping_city}>\"\n",
    "\n",
    "print(\"Enhanced Transaction Class defined.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0f043a",
   "metadata": {},
   "source": [
    "## Step 4: Bulk Loaded (The Merge)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9eebf46",
   "metadata": {},
   "source": [
    "We loop through sales data and **Merge** with promo data using the dictionary lookup.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a49704",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions = []\n",
    "for row in sales_data:\n",
    "    oid = row['Order ID']\n",
    "    # Merge occurs here: fetching matching promo row via key\n",
    "    p_row = promo_data.get(oid) \n",
    "    \n",
    "    t = Transaction(row, p_row)\n",
    "    transactions.append(t)\n",
    "\n",
    "print(f\"Merged and Loaded {len(transactions)} Transaction objects.\")\n",
    "print(\"Sample Merged Object:\", transactions[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993224ca",
   "metadata": {},
   "source": [
    "## Step 5: Quick Profiling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf65fcf6",
   "metadata": {},
   "source": [
    "Profiling now includes the new merged fields.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abb7508",
   "metadata": {},
   "outputs": [],
   "source": [
    "prices = []\n",
    "for t in transactions:\n",
    "    try:\n",
    "        prices.append(float(t.unit_price))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "if prices:\n",
    "    min_price, max_price, mean_price = min(prices), max(prices), sum(prices)/len(prices)\n",
    "else:\n",
    "    min_price = max_price = mean_price = 0.0\n",
    "\n",
    "# Count unique shipping cities\n",
    "unique_cities = {t.shipping_city for t in transactions if t.shipping_city}\n",
    "unique_coupons = {t.coupon_code for t in transactions if t.coupon_code}\n",
    "\n",
    "print(f\"Price Stats -> Min: {min_price:.2f}, Mean: {mean_price:.2f}\")\n",
    "print(f\"Unique Shipping Cities: {len(unique_cities)}\")\n",
    "print(f\"Active Coupon Codes: {unique_coupons}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560ff8ee",
   "metadata": {},
   "source": [
    "## Step 6: Spot the Grime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883bb9f8",
   "metadata": {},
   "source": [
    "New dirty data identified from the merge:\n",
    "1.  **Inconsistent Case**: Some cities might be lowercase (e.g., 'rome' vs 'Rome').\n",
    "2.  **Missing Values**: Some transactions have no coupon code (this is expected, but empty strings need handling).\n",
    "3.  **Data Types**: Numeric fields are still strings.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0a4873",
   "metadata": {},
   "source": [
    "## Step 7: Cleaning Rules\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208ae741",
   "metadata": {},
   "source": [
    "Execute `clean()` which now fixes city casing as well.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9438eead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking dirty city sample\n",
    "dirty_cities = [t.shipping_city for t in transactions if t.shipping_city and t.shipping_city.islower()]\n",
    "print(f\"Lowercase cities found before cleaning: {len(dirty_cities)}\")\n",
    "\n",
    "for t in transactions:\n",
    "    t.clean()\n",
    "\n",
    "dirty_cities_after = [t.shipping_city for t in transactions if t.shipping_city and t.shipping_city.islower()]\n",
    "print(f\"Lowercase cities found after cleaning: {len(dirty_cities_after)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3c5092",
   "metadata": {},
   "source": [
    "## Step 8: Transformations (Coupon Parsing)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8cd1a53",
   "metadata": {},
   "source": [
    "Transform `Coupon Code` into a numeric discount. Rule: 'SAVE10' -> 10.0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7483df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Date Parsing\n",
    "for t in transactions:\n",
    "    if isinstance(t.order_date, str):\n",
    "        try:\n",
    "            t.order_date = datetime.strptime(t.order_date, '%m/%d/%Y')\n",
    "        except ValueError:\n",
    "            t.order_date = None\n",
    "\n",
    "# Coupon Parsing Logic\n",
    "def parse_coupon(code):\n",
    "    if not code: return 0.0\n",
    "    code = code.upper()\n",
    "    if 'SAVE' in code:\n",
    "        return float(code.replace('SAVE', ''))\n",
    "    if 'WELCOME' in code:\n",
    "        return float(code.replace('WELCOME', ''))\n",
    "    if 'SUMMER' in code:\n",
    "        return float(code.replace('SUMMER', ''))\n",
    "    if 'WINTER' in code:\n",
    "        return float(code.replace('WINTER', ''))\n",
    "    return 0.0\n",
    "\n",
    "for t in transactions:\n",
    "    t.discount_amount = parse_coupon(t.coupon_code)\n",
    "\n",
    "print(f\"Sample Coupon: {transactions[0].coupon_code}, Discount: {transactions[0].discount_amount}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11eb9383",
   "metadata": {},
   "source": [
    "## Step 9: Feature Engineering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d715f5",
   "metadata": {},
   "source": [
    "Feature: `Net Revenue` = Total Revenue - Discount.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5899d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in transactions:\n",
    "    # Applying simple flat discount for demonstration\n",
    "    t.net_revenue = t.total_revenue - t.discount_amount\n",
    "    \n",
    "    if t.total_revenue > 0:\n",
    "        t.margin_percentage = (t.total_profit / t.total_revenue) * 100\n",
    "    else:\n",
    "        t.margin_percentage = 0.0\n",
    "\n",
    "print(f\"Sample Net Revenue: {transactions[0].net_revenue:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75211740",
   "metadata": {},
   "source": [
    "## Step 10: Mini-Aggregation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9b06b4",
   "metadata": {},
   "source": [
    "Aggregate Revenue by Shipping City.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8caabaa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rev_by_city = {}\n",
    "for t in transactions:\n",
    "    city = t.shipping_city\n",
    "    if city not in rev_by_city:\n",
    "        rev_by_city[city] = 0.0\n",
    "    rev_by_city[city] += t.net_revenue\n",
    "\n",
    "print(\"Top 5 Cities by Revenue:\")\n",
    "sorted_cities = sorted(rev_by_city.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "for city, rev in sorted_cities:\n",
    "    print(f\"{city}: ${rev:,.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7780c7",
   "metadata": {},
   "source": [
    "## Step 11: Serialization Checkpoint\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f573ec4e",
   "metadata": {},
   "source": [
    "Save to JSON and CSV.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6bcd0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "\n",
    "def transaction_serializer(obj):\n",
    "    if isinstance(obj, datetime):\n",
    "        return obj.strftime('%Y-%m-%d')\n",
    "    return obj.__dict__\n",
    "\n",
    "# JSON\n",
    "with open('../data/processed_transactions.json', 'w') as f:\n",
    "    json.dump(transactions, f, default=transaction_serializer, indent=4)\n",
    "\n",
    "# CSV\n",
    "if transactions:\n",
    "    headers = transactions[0].__dict__.keys()\n",
    "    with open('../data/processed_transactions.csv', 'w', newline='') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=headers)\n",
    "        writer.writeheader()\n",
    "        for t in transactions:\n",
    "            row = t.__dict__.copy()\n",
    "            if isinstance(row['order_date'], datetime):\n",
    "                row['order_date'] = row['order_date'].strftime('%Y-%m-%d')\n",
    "            writer.writerow(row)\n",
    "\n",
    "print(\"Serialization complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545d34d4",
   "metadata": {},
   "source": [
    "## Step 12: Soft Interview Reflection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1bff10",
   "metadata": {},
   "source": [
    "The whiteboard diagram required a **Merge** step, which I simulated by joining Sales Data with a secondary Shipping/Promo dataset. \n",
    "Using a **Hash Map (Dictionary)** for the secondary source allowed me to perform the merge in O(N) time complexity instead of O(N^2), which is critical for scaling data engineering pipelines.\n",
    "This structure mimics a database JOIN operation, ensuring data integrity across the '1st Normal Form' final dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccde428c",
   "metadata": {},
   "source": [
    "## Data Dictionary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ff0988",
   "metadata": {},
   "source": [
    "\n",
    "| Field | Type | Description | Source |\n",
    "|-------|------|-------------|--------|\n",
    "| Order ID | Int | Unique key used to merge the two files | Primary (Sales) + Secondary (Promo) |\n",
    "| Shipping City | String | City to ship to (e.g., \"Tripoli Capital City\") | Secondary (Generated Promo File) |\n",
    "| Coupon Code | String | The raw code (e.g., \"SUMMER15\") | Secondary (Generated Promo File) |\n",
    "| Discount Amount | Float | The numeric value we extracted (e.g., 15.0) | Transformed (Python Function) |\n",
    "| Net Revenue | Float | Revenue minus the discount | Feature Engineering (Math) |\n",
    "| Region | String | Continent/Region | Primary (Sales CSV) |\n",
    "| Country | String | Country Name | Primary (Sales CSV) |\n",
    "| Item Type | String | Product Category | Primary (Sales CSV) |\n",
    "| Sales Channel | String | Online or Offline | Primary (Sales CSV) |\n",
    "| Order Date | Date | Date the order was placed | Primary (Sales CSV) |\n",
    "| Units Sold | Int | Quantity | Primary (Sales CSV) |\n",
    "| Unit Price | Float | Price per item | Primary (Sales CSV) |\n",
    "| Total Revenue | Float | Unit Price * Units Sold | Primary (Sales CSV) |\n",
    "| Total Profit | Float | Total Revenue - Total Cost | Primary (Sales CSV) |\n",
    "| Margin % | Float | Calculated Profit / Revenue | Feature Engineering |\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
